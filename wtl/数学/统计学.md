# 

### 数据分类

- 值数据
  - 连续数据
  - 离散数据
- 分类数据
  - 定类数据
  - 定序数据

#### 通常分析**`离散数值`**、**`连续数值`**时，通常会讨论**四**大方面：

- 集中趋势(Center)

  > 测量值包括如下：

  - 均值或叫平均数(Mean)  $ \overline{x} = \frac{1}{n}\displaystyle\sum_{i=1}^{n}{x_i} $
  - 中位数(Median) （最中间的数）
  - 众数(Mode) (出现次数最多的数)

- 离散程度(Spread)

  > 测量值包括如下：

  - 极差(Range)
  - 四分位差(Interquartile Range (IQR))
  - 标准差(Standard Deviation)
  - 方差(Variance)

- 形状(Shape)

- 异常值(Outliers)



#### 测量离散数据方式之一 —— 五数概括法

- 最小值；`数据集中的最小数字`
- 第1四分位数(Q1)；`25％的数据低于此值。`
- 中位数(Q2)；`50％的数据低于此值。`
- 第3四分位数(Q3)；`75％的数据低于此值。`
- 最大值。

> 极差(Range) = 最大值 - 最小值
>
> 四分位差(Interquartile Range (IQR)) = Q3 - Q1

##### 奇数集

![image-20180925155628928](/Users/wangtianli/Library/Application Support/typora-user-images/image-20180925155628928.png)

###### 偶数集

![image-20180925155758825](/Users/wangtianli/Library/Application Support/typora-user-images/image-20180925155758825.png)

#### 方差

> **方差**（**Variance**），[应用数学](https://zh.wikipedia.org/wiki/%E6%87%89%E7%94%A8%E6%95%B8%E5%AD%B8)里的专有名词。在[概率论](https://zh.wikipedia.org/wiki/%E6%A6%82%E7%8E%87%E8%AE%BA)和[统计学](https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E5%AD%A6)中，一个[随机变量](https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F)的**方差**描述的是它的离散程度，也就是该变量离其[期望值](https://zh.wikipedia.org/wiki/%E6%9C%9F%E6%9C%9B%E5%80%BC)的距离。一个实随机变量的方差也称为它的[二阶矩](https://zh.wikipedia.org/wiki/%E7%9F%A9_(%E6%95%B8%E5%AD%B8))或二阶中心动差，恰巧也是它的二阶累积量。这里把复杂说白了，就是将各个误差将之平方（而非取绝对值，使之肯定为正数），相加之后再除以总数，透过这样的方式来算出各个数据分布、零散（相对中心点）的程度。继续延伸的话，方差的[算术平方根](https://zh.wikipedia.org/wiki/%E7%AE%97%E6%9C%AF%E5%B9%B3%E6%96%B9%E6%A0%B9)称为该随机变量的**标准差**（此为相对各个数据点间）。
>
> $ \frac{1}{n}\displaystyle\sum_{i=1}^{n}{(X_i - \overline{X})^2}$  
>
>   - 总体方差 用  $\sigma^2$ 表示 
>   - 

#### 标准差

> 中文环境中又常称[均方差](https://baike.baidu.com/item/%E5%9D%87%E6%96%B9%E5%B7%AE/5458588)，是离均差平方的算术平均数的平方根，用σ表示。标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。

例如：`{10,14,10,6}`集合的标准差就是下面这样：

$ \sqrt{\frac{1}{n}\displaystyle\sum_{i=1}^{n}{(X_i - \overline{X})^2}}$ =  $\sqrt{8}$= 2.83  

### 辛普森悖论



| 学院   | 女生申请 | 女生录取 | 女生录取率 | 男生申请 | 男生录取 | 男生录取率 | 合计申请 | 合计录取 | 合计录取率 |
| ------ | -------- | -------- | ---------- | -------- | -------- | ---------- | -------- | -------- | ---------- |
|        |          |          |            |          |          |            |          |          |            |
| 商学院 | 100      | 49       | 49%        | 20       | 15       | 75%        | 120      | 64       | 53.3%      |
| 法学院 | 20       | 1        | 5%         | 100      | 10       | 10%        | 120      | 11       | 9.2%       |
| 总计   | 120      | 50       | 42%        | 120      | 25       | 21%        | 240      | 75       | 31.3%      |

你知道为什么个别录取率男皆大于女，但是总体录取率男却远小于女吗？

此例这就是统计上著名的辛普森悖论(Simpson's Paradox)



### 概率

抛硬币，抛掷一次出现一次正面的概率是0.5，抛掷两次出现一次正面的概率是 0.5 * 0.5 ，抛掷三次出现一次正面的概率是 0.375 ？

下面是出现抛掷三次只出现一次正面的概率解释： 

> 有三次 会出现一次正的情况
>
> 如果 抛掷一次出现一次正面的概率是0.5，抛掷三次出现一次正面的概率是0.288 = 0.4 * 0.6 * 0.4 * 3

|   1次    |   2次    |   3次    | 概率（0.5） | 概率（0.6）    |
| :------: | :------: | :------: | :---------: | -------------- |
|    正    |    正    |    正    |    0.125    | 0.6 * 0.6 *0.6 |
|    正    |    正    |    反    |    0.125    | 0.6 * 0.6 *0.4 |
|    正    |    反    |    正    |    0.125    | 0.6 * 0.4 *0.6 |
| **`正`** |    反    |    反    |    0.125    | 0.6 * 0.4 *0.4 |
|    反    |    正    |    正    |    0.125    | 0.4 * 0.6 *0.6 |
|    反    |    反    | **`正`** |    0.125    | 0.4 * 0.4 *0.6 |
|    反    | **`正`** |    反    |    0.125    | 0.4 * 0.6 *0.4 |
|    反    |    反    |    反    |    0.125    | 0.4 * 0.4 *0.4 |



#### 二项分布

> 在[概率论](https://zh.wikipedia.org/wiki/%E6%A6%82%E7%8E%87%E8%AE%BA)和[统计学](https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E5%AD%A6)中，**二项分布**（英语：Binomial distribution）是*n*个[独立](https://zh.wikipedia.org/wiki/%E7%B5%B1%E8%A8%88%E7%8D%A8%E7%AB%8B%E6%80%A7)的是/非试验中成功的次数的[离散概率分布](https://zh.wikipedia.org/wiki/%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83)，其中每次试验的成功[概率](https://zh.wikipedia.org/wiki/%E6%A6%82%E7%8E%87)为*p*。这样的单次成功/失败试验又称为[伯努利试验](https://zh.wikipedia.org/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E8%A9%A6%E9%A9%97)。实际上，当*n* = 1时，二项分布就是[伯努利分布](https://zh.wikipedia.org/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83)。二项分布是[显著性差异](https://zh.wikipedia.org/wiki/%E6%98%BE%E8%91%97%E6%80%A7%E5%B7%AE%E5%BC%82)的[二项试验](https://zh.wikipedia.org/w/index.php?title=%E4%BA%8C%E9%A1%B9%E8%AF%95%E9%AA%8C&action=edit&redlink=1)的基础。

- 概率质量函数

  > 其中**n**是事件的数量，**x**是“成功”的数量，**p**是“成功”的概率。

  $P(X=x)=\frac {n!}{x!(n-x)!}p^{x}(1-p)^{n-x} $


##### 条件概率

> **条件概率**（英语：conditional probability）就是[事件](https://zh.wikipedia.org/wiki/%E4%BA%8B%E4%BB%B6)*A*在另外一个事件*B*已经发生条件下的发生[概率](https://zh.wikipedia.org/wiki/%E6%A6%82%E7%8E%87)。条件概率表示为*P*（*A*|*B*），读作“在*B*条件下*A*的概率”。

##### 联合概率

> **联合概率**表示两个事件共同发生的概率。*A*与*B*的联合概率表示为 $ \displaystyle P(A\cap B) $或者$\displaystyle P(A,B)$或者$\displaystyle P(AB)$。

##### **边缘概率**

> **边缘概率**是某个事件发生的概率。边缘概率是这样得到的：在联合概率中，把最终结果中不需要的那些事件合并成其事件的[全概率](https://zh.wikipedia.org/wiki/%E5%85%A8%E6%A6%82%E7%8E%87)而消失（对离散随机变量用求和得全概率，对连续随机变量用积分得全概率）。这称为**边缘化**（**marginalization**）。*A*的边缘概率表示为*P*（*A*），*B*的边缘概率表示为*P*（*B*）。

#### 贝叶斯定理

